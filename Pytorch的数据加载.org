* Pytorch的数据加载
Pytorch中数据读取主要有三个类：
- Dataset类
- DataLoader类
- DataLoaderIter类
三者的关系：前者被装进后者。
** ~torch.utils.data.Dataset~ 类
~torch.utils.data.Dataset~ 是一个抽象类，自定义的Dataset要继承它，
并实现两个成员方法： ~__get_item__()~, ~__len__()~ .第一个最重要，
它决定了每次怎么读取数据。以自定义的MNIST数据集为例：
#+BEGIN_SRC python
from torch.utils.data import Dataset
import pandas as pd

class MNIST_dataset(Dataset):
    """customized MNIST data set"""
    def __init__(self, file_path='~/data/', header=None, transform=None):
        df = pd.csv(file_path, header=header, dtype='uint8') # 必须要指定数据类型，也可以是np.float32
        self.data = df.iloc[:, 1:].values.reshape(-1, 28, 28)
        self.label = df.iloc[:, 0].values
        self.transform = transform

    def __len__(self):
        return len(self.data)

    def __get_item__(self, idx):
        data = self.data
        if self.transform is not None:
            data = self.transform(data)
        return data[idx], self.label[idx]
#+END_SRC
实例化数据类：
#+BEGIN_SRC python
# 定义数据变换
transform = transforms.Compose([transforms.ToTensor(),
                                transforms.Normalize((0.1307,), (0.3081,)) # MNIST数据集特有的均值和方差
                               ])
# 实例化数据集类
trainset = MNIST_data('/home/ligy/Documents/handson_ML_practice/datasets/MNIST/train.csv', 
                       transform = transform)
testset = MNIST_data('/home/ligy/Documents/handson_ML_practice/datasets/MNIST/test.csv', 
                       transform = transform
                     )
#+END_SRC

** ~torch.utils.data.DataLoader~ 类
将数据集和抽样器组合了起来，提供了一个数据集的可迭代对象。

#+BEGIN_SRC python
torch.utils.data.DataLoader(dataset,
                            batch_size=1,
                            shuffle=False,
                            sampler=None,
                            batch_sampler=None,
                            num_workers=0,
                            collate_fn=<function default_collate>,
                            pin_memory=False,
                            drop_last=False)
#+END_SRC
参数:
    - dataset (Dataset): 用以加载数据的数据集
    - batch_size (int, optional): 每个batch加载的样本数量，默认为1。
    - shuffle (bool, optional): ~True~ 时第个epoch将再次打乱样本顺序，默认为 ~False~
    - sampler (Sampler, optional): 定义了从数据集中抽样的策略。如果指定，shuffle必须为False
    - batch_sampler (Sampler, optional): 与sampler类似，但每次返回一批样本指标，
      与batch_size，shuffle, sampler, drop_last相互排斥。
    - num_workers (int, optional): 加载时使用多少子线程。0代表数据会被加载进主进程。默认值为0。
    - collate_fn (callable, optional): 将样本列表合并成一个mini-batch的形式。用于从map-style的
      数据集中批量加载数据时。
    - pin_memory (bool, optional):如果为True, 数据加载器将在返回张量前将他们复制到CUDA的pinned memory中。
    - drop_last (bool, optional): 如果为True, 将丢掉最后一个不完整的批次（如果数据集大小不能被batch_size整除的话）。
      默认为False.
    - timeout (numeric, optional): 如果为正数，给定从worker收集批次的时间上限。非负，默认为0.
    - worker_init_fn (callable, optional): 默认值为None.
