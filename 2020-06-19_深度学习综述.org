* 深度学习综述
深度学习即表征学习是机器学习的一个分支或子领域，大多数人认为近代深度学习方法是从2006
开始发展起来的，2006年Geoffrey Hinton提出了深度学习的概念。
** 历史发展
- 1943 年,McCulloch和Pitts提出MP神经元数学模型。
- 1958年,第一代神经网络单层感知器由 Rosenblatt提出,第一代神经网络能够区分三角形、
  正方形等基本形状。
- 1969年,Minsky发表感知器专著:单层感知器无法解决异或 XOR问题。
- 1986 年,Hinton等提出第二代神经网络,将原始单一固定的特征层替换成多个隐藏层,
  激活函数采用Sigmoid函数,利用误差的反向传播算法来训练模型,能有效解决非线性分类问题
- 1989年,Cybenko 和 Hornik等证明了万能逼近定理(universal approximation
  theorem): 任何函数都可以被三层神经网络以任意精度逼近。
- LeCun等发明了卷积神经网络用来识别手写体,当时需要 3天来训练模型。
- 1991年,反向传播算法被指出存在梯度消失问题。
- 1995年Cortes与Vapnik发明的支持向量机。
- 2006年,Hinton等提出自动编码器来降低数据维度，并提出预训练。
- Poultney等用基于能量的模型来有效学习稀疏表示。
- 2011年，Glorot等提出ReLU激活函数能有效抑制梯度消失问题。
- 2014年Choromanska等证明局部极小值问题通常来说不是严重的问题。

深度学习模型与浅层机器学习模型之间存在重要区别。浅层机器学习模型不使用分布式表示，
而且需要人为提取特征，模型本身只是根据特征进行分类或预测，人为提取的特征好坏很大程度上决
定了整个系统的好坏．特征提取需要专业的领域知识，而且特征提取、特征工程需要花费大量时间．
深度学习是一种表示学习，能够学到数据更高层次的抽象表示，能够自动从数据中提取特征．
而且深度学习里的隐藏层相当于是输入特征的线性组合，隐藏层与输入层之间的权重相当于
输入特征在线性组合中的权重．
