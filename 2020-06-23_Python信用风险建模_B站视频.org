* Python信用风险建模
** 第十四集 因变量与自变量
要对PD, LGD, EAD建立模型，它们都是回归模型。
- PD: 逻辑回归(Logistic regression)
- LGD: Beta回归(Beta regression)
- EAD: Beta回归(Beta regression)
不同模型的因变量：
- PD: Loan status列
- LGD: recoveries列
- EAD: total recovered principal列
不同自变量的预处理方式不同：
- 离散变量：categorical, 取有限值
  + 无序离散变量： ~按离散值处理~
  + 有序离散变量： ~按离散值处理~
- 连续变量：数值型，可以取无限个值， ~按离散值处理~

PD模型要求所有的自变量都必须是categorical，这是为了方便呈现和易于转化成评分卡。
所以预处理就是要把所有变量转化成区间形式。

- 对于离散变量有时要先进行区间合并，再转化成dummy变量。
- 对于连续变量要先fine classing, 再coarse classing, 再转化成dummy变量
再将这些dummy变量送入模型中。
** 第十五集 将数据载入到Python
** 第十六集 预处理一些连续变量
首先要确保所有的连续变量是numeric类型。
** 第十七集 预处理一些离散变量
#+BEGIN_SRC python
pd.get_dummies(loan_data['grade'])
pd.get_dummies(loan_data['grade'], prefix='grade', prefix_sep='_')

loan_data_dummies = [pd.get_dummies(loan_data['grade'], prefix = 'grade', prefix_sep = ':'),
                     pd.get_dummies(loan_data['sub_grade'], prefix = 'sub_grade', prefix_sep = ':'),
                     pd.get_dummies(loan_data['home_ownership'], prefix = 'home_ownership', prefix_sep = ':'),
                     pd.get_dummies(loan_data['verification_status'], prefix = 'verification_status', prefix_sep = ':'),
                     pd.get_dummies(loan_data['loan_status'], prefix = 'loan_status', prefix_sep = ':'),
                     pd.get_dummies(loan_data['purpose'], prefix = 'purpose', prefix_sep = ':'),
                     pd.get_dummies(loan_data['addr_state'], prefix = 'addr_state', prefix_sep = ':'),
                     pd.get_dummies(loan_data['initial_list_status'], prefix = 'initial_list_status', prefix_sep = ':')]
loan_data_dummies = pd.concat(loan_data_dummies, axis = 1)
#+END_SRC
** 第十八集 预处理缺失值
** 第十九集 PD模型是什么样的
好坏定义（违约定义）：一般定义为拖欠还款超过90天。
[[file:images/logistic0.png]]

[[file:images/logistic.png]]

监管者要求PD模型要有可解释性，所以它的输入变量都是dummy变量。
** 第二十集 根据好坏定义建立因变量
~np.where()~ 类似于 ~if~ 语法。用 ~apply~ 也可以实现：
#+BEGIN_SRC python
good = ['Fully Paid', 'Current', 'In Grace Period', 'Late (16-30 days)',
       'Does not meet the credit policy. Status:Fully Paid']
df['good_bad'] = df.loan_status.apply(lambda x: 1 if x in good else 0)
#+END_SRC
** 第二十一集 连续变量离散化，Fine classing, WOE和Coarse classing
先将连续变量进行初始离散，再计算每个离散区间的WoE。

WoE_i = ln(%good_{i}/%bad_{i})

WoE_{i}的绝对值越大，则这个离散区间区分好坏的能力越强。再根据初始的离散区间构造
新的区间，这个过程称为Coarse classing.

构造新区间的方法为将WoE值相近的区间合并，以减少区间数量。再将新的区间转化成dummy变量，
送入PD模型中。
** 第二十二集 信息值IV
反映自变量对因变量的预测能力，可以用来pre-selection，即特征选择。但是本视频不会用IV
值来选择特征，因为我们将用更高级的方法。但这是个很重要的量，经常用到。
[[file:images/iv.png]]
** 第二十三集 分离测试集
用sklearn的train_test_split
** 第二十四集 计算grade变量的WoE
#+BEGIN_SRC python
# 计算每个grade的分立取值对应的因变量target的个数
df['good_bad'] = df.groupby('grade', as_index=false)['target'].count()
#+END_SRC
** 第二十五集 自动计算离散变量的WoE和IV值
定义函数来自动处理离散变量，函数原型为：
#+BEGIN_SRC python
def woe_discrete(df, discrete_variable_name, target_variable_df):
    # 计算WoE
    df['WoE'] = #...
    # 计算IV
    df['IV'] = #...
    return df
#+END_SRC
DataFrame df中包含了以字符串命名的离散变量discrete_variable_name， 因变量单独存在以target_variable_df
命名的DataFrame中。
** 第二十六集 可视化离散变量的WoE
定义绘图函数 ~plot_woe(df_woe, rotation_x_label=0)~
** 第二十七集 根据WoE合并离散变量的分立取值（一）
合并的依据：？
- 样本数太少的应该合并到其他组
- 样本数大的应该单独分为一组
- WoE值相近的可以分为一个组
直接将需要合并的离散变量的分立取值对应的dummy变量相加！（不懂为什么？）
#+BEGIN_SRC python
# 合并grade A和B
df['AB'] = sum(df['grade:A'], df['grade:B'])
#+END_SRC

** 第二十八集 根据WoE合并离散变量的分立取值（二）
风险管理的保守态度，缺失信息则假设为风险最高。将合并好的分组转化成dummy变量，
并将WoE最小的分组作为参考，以比较回归模型的能力。
